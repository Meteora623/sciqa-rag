import os
import faiss
import pickle
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

# è®¾å®šè·¯å¾„
text_folder = "../data/texts"
index_path = "faiss_index"
embedding_model_name = "all-MiniLM-L6-v2"

# åŠ è½½åµŒå…¥æ¨¡å‹ï¼ˆSentence-Transformersï¼‰
model = SentenceTransformer(embedding_model_name)

# æ”¶é›†æ‰€æœ‰æ–‡æœ¬å—
documents = []
file_names = os.listdir(text_folder)
for file in file_names:
    with open(os.path.join(text_folder, file), "r", encoding="utf-8") as f:
        text = f.read()
        chunks = [chunk.strip() for chunk in text.split("\n\n") if len(chunk.strip()) > 50]
        documents.extend(chunks)

# ç”ŸæˆåµŒå…¥
print(f"ğŸ“„ æ­£åœ¨ä¸º {len(documents)} æ®µæ–‡æœ¬ç”ŸæˆåµŒå…¥å‘é‡...")
embeddings = model.encode(documents, show_progress_bar=True)

# æ„å»ºå¹¶ä¿å­˜ FAISS ç´¢å¼•
dim = embeddings.shape[1]
index = faiss.IndexFlatL2(dim)
index.add(embeddings)

os.makedirs(index_path, exist_ok=True)
faiss.write_index(index, os.path.join(index_path, "docs.index"))

with open(os.path.join(index_path, "chunks.pkl"), "wb") as f:
    pickle.dump(documents, f)

print("å‘é‡ç´¢å¼•æ„å»ºå®Œæˆï¼Œä¿å­˜äº ./rag/faiss_index/")